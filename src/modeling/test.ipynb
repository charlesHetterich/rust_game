{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from model_arc import BallPolicy\n",
    "torch.mps.current_allocated_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5937803005817712"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mps.profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425984"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mps.driver_allocated_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.jit.load(\"ball_policy.pt\", map_location=torch.device('cpu'))\n",
    "n_balls = 50\n",
    "nb_features=4\n",
    "in_f = (n_balls + 1) * nb_features\n",
    "model = BallPolicy(n_balls = n_balls, nb_features=nb_features, n_actions=4, n_layers=2)\n",
    "model = model.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01472163200378418\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "batch_size = 32\n",
    "t = time()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-8)\n",
    "data = torch.rand(batch_size, in_f).to('mps')\n",
    "# for _ in range(60):\n",
    "loss = model(data).sum()\n",
    "# print(loss)\n",
    "loss.backward()\n",
    "optim.step()\n",
    "delta  = time() - t\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8145, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=1e-8)\n",
    "data = torch.rand(1, 1004).to('cpu') * 1000000000\n",
    "loss = model(data).sum()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1607, 0.6558, 0.1795, 0.6435, 0.5817, 0.7773, 0.2754, 0.6279, 0.4268,\n",
      "         0.3380, 0.9985, 0.3087, 0.1169, 0.9919, 0.7456, 0.4179, 0.7269, 0.7882,\n",
      "         0.9452, 0.9267, 0.2000, 0.3957, 0.0325, 0.5733, 0.0043, 0.4618, 0.9501,\n",
      "         0.1934, 0.1906, 0.1742, 0.9788, 0.5099, 0.8030, 0.1362, 0.8860, 0.6982,\n",
      "         0.9043, 0.7401, 0.8275, 0.8636, 0.0550, 0.0833, 0.5711, 0.4348, 0.2975,\n",
      "         0.4235, 0.3399, 0.9667, 0.2835, 0.1916, 0.7493, 0.8560, 0.4503, 0.9696,\n",
      "         0.4613, 0.9016, 0.8486, 0.0912, 0.4481, 0.9865, 0.5720, 0.9743, 0.7210,\n",
      "         0.0758, 0.0845, 0.2558, 0.9505, 0.7565, 0.6046, 0.4338, 0.9569, 0.7902,\n",
      "         0.8656, 0.6070, 0.8447, 0.1914, 0.0463, 0.2863, 0.8697, 0.5480, 0.0542,\n",
      "         0.0481, 0.6061, 0.9848, 0.0304, 0.7185, 0.7259, 0.9627, 0.4677, 0.3502,\n",
      "         0.8991, 0.4367, 0.4507, 0.2996, 0.7822, 0.1324, 0.6747, 0.9638, 0.4812,\n",
      "         0.2542, 0.5442, 0.2416, 0.6191, 0.5733, 0.3336, 0.5777, 0.9326, 0.9300,\n",
      "         0.5902, 0.6570, 0.5770, 0.5882, 0.5874, 0.7913, 0.2945, 0.0401, 0.8513,\n",
      "         0.0873, 0.7874, 0.4045, 0.2878, 0.4952, 0.6289, 0.4367, 0.3436, 0.0073,\n",
      "         0.4247, 0.3890, 0.6800, 0.9996, 0.7276, 0.1111, 0.6986, 0.1963, 0.1007,\n",
      "         0.1607, 0.2338, 0.8964, 0.7699, 0.7518, 0.9732, 0.2537, 0.8537, 0.0894,\n",
      "         0.1388, 0.3786, 0.6887, 0.3225, 0.3886, 0.7248, 0.4669, 0.8208, 0.3115,\n",
      "         0.1144, 0.0379, 0.9320, 0.4840, 0.9302, 0.8468, 0.6511, 0.6557, 0.2242,\n",
      "         0.1367, 0.7712, 0.9496, 0.3392, 0.2912, 0.9426, 0.8340, 0.7606, 0.5123,\n",
      "         0.8822, 0.6298, 0.1458, 0.6424, 0.1994, 0.5404, 0.7043, 0.7596, 0.7476,\n",
      "         0.6809, 0.2287, 0.7192, 0.8255, 0.5167, 0.7990, 0.8470, 0.3438, 0.7301,\n",
      "         0.9654, 0.9011, 0.6960, 0.9916, 0.7539, 0.2406, 0.4325, 0.1832, 0.1019,\n",
      "         0.2261, 0.2812, 0.0698, 0.6707, 0.0209, 0.8455]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0254,  0.0652,  0.0072,  0.0306]], device='mps:0',\n",
       "       grad_fn=<DifferentiableGraphBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
